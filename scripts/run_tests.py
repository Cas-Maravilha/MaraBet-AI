#!/usr/bin/env python3
"""
Script para executar testes do MaraBet AI
Suporte para diferentes tipos de testes e configuraÃ§Ãµes
"""

import os
import sys
import subprocess
import argparse
import time
from pathlib import Path

# Adiciona o diretÃ³rio raiz ao path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def run_command(command, description=""):
    """Executa comando e retorna resultado"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ {description}")
    print(f"{'='*60}")
    print(f"Comando: {command}")
    print()
    
    start_time = time.time()
    result = subprocess.run(command, shell=True, capture_output=True, text=True)
    end_time = time.time()
    
    duration = end_time - start_time
    
    print(f"â±ï¸  DuraÃ§Ã£o: {duration:.2f} segundos")
    print(f"ğŸ“Š CÃ³digo de saÃ­da: {result.returncode}")
    
    if result.stdout:
        print(f"\nğŸ“¤ SaÃ­da padrÃ£o:")
        print(result.stdout)
    
    if result.stderr:
        print(f"\nâŒ Erro:")
        print(result.stderr)
    
    return result.returncode == 0, duration

def run_unit_tests(parallel=False, coverage=True, verbose=False):
    """Executa testes unitÃ¡rios"""
    print("ğŸ§ª Executando testes unitÃ¡rios...")
    
    command = "pytest tests/test_units/ -m unit"
    
    if parallel:
        command += " -n auto"
    
    if coverage:
        command += " --cov=. --cov-report=html:htmlcov/unit --cov-report=term-missing"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes UnitÃ¡rios")
    
    if success:
        print(f"âœ… Testes unitÃ¡rios executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes unitÃ¡rios falharam em {duration:.2f}s")
    
    return success

def run_integration_tests(parallel=False, coverage=True, verbose=False):
    """Executa testes de integraÃ§Ã£o"""
    print("ğŸ”— Executando testes de integraÃ§Ã£o...")
    
    command = "pytest tests/test_integration/ -m integration"
    
    if parallel:
        command += " -n auto"
    
    if coverage:
        command += " --cov=. --cov-report=html:htmlcov/integration --cov-report=term-missing"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes de IntegraÃ§Ã£o")
    
    if success:
        print(f"âœ… Testes de integraÃ§Ã£o executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes de integraÃ§Ã£o falharam em {duration:.2f}s")
    
    return success

def run_ml_tests(parallel=False, coverage=True, verbose=False):
    """Executa testes de ML"""
    print("ğŸ¤– Executando testes de Machine Learning...")
    
    command = "pytest tests/ -m ml"
    
    if parallel:
        command += " -n auto"
    
    if coverage:
        command += " --cov=. --cov-report=html:htmlcov/ml --cov-report=term-missing"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes de ML")
    
    if success:
        print(f"âœ… Testes de ML executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes de ML falharam em {duration:.2f}s")
    
    return success

def run_auth_tests(parallel=False, coverage=True, verbose=False):
    """Executa testes de autenticaÃ§Ã£o"""
    print("ğŸ” Executando testes de autenticaÃ§Ã£o...")
    
    command = "pytest tests/ -m auth"
    
    if parallel:
        command += " -n auto"
    
    if coverage:
        command += " --cov=. --cov-report=html:htmlcov/auth --cov-report=term-missing"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes de AutenticaÃ§Ã£o")
    
    if success:
        print(f"âœ… Testes de autenticaÃ§Ã£o executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes de autenticaÃ§Ã£o falharam em {duration:.2f}s")
    
    return success

def run_api_tests(parallel=False, coverage=True, verbose=False):
    """Executa testes de API"""
    print("ğŸŒ Executando testes de API...")
    
    command = "pytest tests/ -m api"
    
    if parallel:
        command += " -n auto"
    
    if coverage:
        command += " --cov=. --cov-report=html:htmlcov/api --cov-report=term-missing"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes de API")
    
    if success:
        print(f"âœ… Testes de API executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes de API falharam em {duration:.2f}s")
    
    return success

def run_all_tests(parallel=False, coverage=True, verbose=False):
    """Executa todos os testes"""
    print("ğŸ¯ Executando todos os testes...")
    
    command = "pytest tests/"
    
    if parallel:
        command += " -n auto"
    
    if coverage:
        command += " --cov=. --cov-report=html:htmlcov/all --cov-report=term-missing --cov-report=xml:coverage.xml"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Todos os Testes")
    
    if success:
        print(f"âœ… Todos os testes executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Alguns testes falharam em {duration:.2f}s")
    
    return success

def run_specific_test(test_path, verbose=False):
    """Executa teste especÃ­fico"""
    print(f"ğŸ¯ Executando teste especÃ­fico: {test_path}")
    
    command = f"pytest {test_path}"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, f"Teste EspecÃ­fico: {test_path}")
    
    if success:
        print(f"âœ… Teste executado com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Teste falhou em {duration:.2f}s")
    
    return success

def run_slow_tests(parallel=False, verbose=False):
    """Executa apenas testes lentos"""
    print("ğŸŒ Executando testes lentos...")
    
    command = "pytest tests/ -m slow"
    
    if parallel:
        command += " -n auto"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes Lentos")
    
    if success:
        print(f"âœ… Testes lentos executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes lentos falharam em {duration:.2f}s")
    
    return success

def run_external_tests(parallel=False, verbose=False):
    """Executa testes que dependem de APIs externas"""
    print("ğŸŒ Executando testes externos...")
    
    command = "pytest tests/ -m external"
    
    if parallel:
        command += " -n auto"
    
    if verbose:
        command += " -v -s"
    
    success, duration = run_command(command, "Testes Externos")
    
    if success:
        print(f"âœ… Testes externos executados com sucesso em {duration:.2f}s")
    else:
        print(f"âŒ Testes externos falharam em {duration:.2f}s")
    
    return success

def generate_coverage_report():
    """Gera relatÃ³rio de cobertura"""
    print("ğŸ“Š Gerando relatÃ³rio de cobertura...")
    
    command = "coverage html -d htmlcov/final"
    success, duration = run_command(command, "RelatÃ³rio de Cobertura")
    
    if success:
        print(f"âœ… RelatÃ³rio de cobertura gerado em {duration:.2f}s")
        print("ğŸ“ RelatÃ³rio disponÃ­vel em: htmlcov/final/index.html")
    else:
        print(f"âŒ Falha ao gerar relatÃ³rio de cobertura em {duration:.2f}s")
    
    return success

def check_test_environment():
    """Verifica ambiente de teste"""
    print("ğŸ” Verificando ambiente de teste...")
    
    # Verificar se pytest estÃ¡ instalado
    try:
        import pytest
        print(f"âœ… pytest {pytest.__version__} instalado")
    except ImportError:
        print("âŒ pytest nÃ£o estÃ¡ instalado")
        return False
    
    # Verificar se dependÃªncias estÃ£o instaladas
    try:
        import pandas
        import numpy
        import sklearn
        print("âœ… DependÃªncias de ML instaladas")
    except ImportError as e:
        print(f"âŒ DependÃªncia de ML nÃ£o encontrada: {e}")
        return False
    
    # Verificar se Redis estÃ¡ disponÃ­vel
    try:
        import redis
        r = redis.Redis(host='localhost', port=6379, db=1)
        r.ping()
        print("âœ… Redis disponÃ­vel")
    except Exception:
        print("âš ï¸  Redis nÃ£o disponÃ­vel (alguns testes podem falhar)")
    
    # Verificar se banco de dados estÃ¡ disponÃ­vel
    try:
        from armazenamento.banco_de_dados import SessionLocal
        db = SessionLocal()
        db.close()
        print("âœ… Banco de dados disponÃ­vel")
    except Exception as e:
        print(f"âŒ Banco de dados nÃ£o disponÃ­vel: {e}")
        return False
    
    print("âœ… Ambiente de teste verificado")
    return True

def main():
    """FunÃ§Ã£o principal"""
    parser = argparse.ArgumentParser(description="Executar testes do MaraBet AI")
    
    parser.add_argument(
        "test_type",
        choices=[
            "unit", "integration", "ml", "auth", "api", 
            "all", "slow", "external", "specific"
        ],
        help="Tipo de teste a executar"
    )
    
    parser.add_argument(
        "--test-path",
        help="Caminho para teste especÃ­fico (usado com --test-type specific)"
    )
    
    parser.add_argument(
        "--parallel",
        action="store_true",
        help="Executar testes em paralelo"
    )
    
    parser.add_argument(
        "--no-coverage",
        action="store_true",
        help="NÃ£o gerar relatÃ³rio de cobertura"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="SaÃ­da verbosa"
    )
    
    parser.add_argument(
        "--check-env",
        action="store_true",
        help="Verificar ambiente antes de executar testes"
    )
    
    parser.add_argument(
        "--coverage-only",
        action="store_true",
        help="Apenas gerar relatÃ³rio de cobertura"
    )
    
    args = parser.parse_args()
    
    # Verificar ambiente se solicitado
    if args.check_env:
        if not check_test_environment():
            print("âŒ Ambiente de teste nÃ£o estÃ¡ pronto")
            sys.exit(1)
    
    # Apenas gerar cobertura se solicitado
    if args.coverage_only:
        generate_coverage_report()
        return
    
    # ConfiguraÃ§Ãµes
    coverage = not args.no_coverage
    parallel = args.parallel
    verbose = args.verbose
    
    # Executar testes baseado no tipo
    success = False
    start_time = time.time()
    
    if args.test_type == "unit":
        success = run_unit_tests(parallel, coverage, verbose)
    elif args.test_type == "integration":
        success = run_integration_tests(parallel, coverage, verbose)
    elif args.test_type == "ml":
        success = run_ml_tests(parallel, coverage, verbose)
    elif args.test_type == "auth":
        success = run_auth_tests(parallel, coverage, verbose)
    elif args.test_type == "api":
        success = run_api_tests(parallel, coverage, verbose)
    elif args.test_type == "all":
        success = run_all_tests(parallel, coverage, verbose)
    elif args.test_type == "slow":
        success = run_slow_tests(parallel, verbose)
    elif args.test_type == "external":
        success = run_external_tests(parallel, verbose)
    elif args.test_type == "specific":
        if not args.test_path:
            print("âŒ Caminho do teste especÃ­fico Ã© obrigatÃ³rio")
            sys.exit(1)
        success = run_specific_test(args.test_path, verbose)
    
    end_time = time.time()
    total_duration = end_time - start_time
    
    # Gerar relatÃ³rio de cobertura se solicitado
    if coverage and success:
        generate_coverage_report()
    
    # Resultado final
    print(f"\n{'='*60}")
    if success:
        print(f"ğŸ‰ Testes executados com sucesso em {total_duration:.2f}s")
        sys.exit(0)
    else:
        print(f"ğŸ’¥ Testes falharam em {total_duration:.2f}s")
        sys.exit(1)

if __name__ == "__main__":
    main()
