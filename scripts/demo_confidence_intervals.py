#!/usr/bin/env python3
"""
Demonstra√ß√£o de Intervalos de Confian√ßa - MaraBet AI
Script de demonstra√ß√£o do sistema de intervalos de confian√ßa
"""

import os
import sys
import argparse
import logging
import numpy as np
import pandas as pd
from datetime import datetime, timedelta

# Adicionar o diret√≥rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from confidence import (
    ConfidenceCalculator, UncertaintyAnalyzer, ConfidenceVisualizer,
    PredictionIntervals, BootstrapConfidence
)

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def generate_sample_data(n_predictions: int = 100) -> tuple:
    """
    Gera dados de exemplo para demonstra√ß√£o
    
    Args:
        n_predictions: N√∫mero de previs√µes
        
    Returns:
        Tupla com (predictions, actual_values, historical_errors)
    """
    try:
        np.random.seed(42)
        
        # Gerar previs√µes (probabilidades entre 0.3 e 0.9)
        base_predictions = np.random.uniform(0.3, 0.9, n_predictions)
        
        # Adicionar ru√≠do para simular incerteza do modelo
        model_uncertainty = np.random.normal(0, 0.05, n_predictions)
        predictions = np.clip(base_predictions + model_uncertainty, 0.1, 0.95)
        
        # Gerar valores reais (com algum vi√©s sistem√°tico)
        systematic_bias = 0.02  # Vi√©s de 2%
        noise = np.random.normal(0, 0.08, n_predictions)
        actual_values = np.clip(predictions + systematic_bias + noise, 0, 1)
        
        # Gerar erros hist√≥ricos para cada previs√£o
        historical_errors = []
        for i in range(n_predictions):
            # Simular erros hist√≥ricos com distribui√ß√£o normal
            n_historical = np.random.randint(10, 50)
            historical_error = np.random.normal(0, 0.1, n_historical)
            historical_errors.append(historical_error.tolist())
        
        return predictions.tolist(), actual_values.tolist(), historical_errors
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao gerar dados de exemplo: {e}")
        return [], [], []

def demo_confidence_calculator():
    """Demonstra o calculador de intervalos de confian√ßa"""
    try:
        logger.info("üîç Demonstra√ß√£o do ConfidenceCalculator")
        
        # Criar calculador
        calculator = ConfidenceCalculator()
        
        # Exemplo 1: Previs√£o √∫nica
        logger.info("\nüìä Exemplo 1: Previs√£o √∫nica")
        prediction = 0.75
        interval = calculator.calculate_confidence_interval([prediction])
        
        print(f"Previs√£o: {prediction:.3f}")
        print(f"Intervalo de 95%: {interval.lower_bound:.3f} - {interval.upper_bound:.3f}")
        print(f"Formato: {calculator.format_confidence_interval(interval)}")
        
        # Exemplo 2: M√∫ltiplas previs√µes
        logger.info("\nüìä Exemplo 2: M√∫ltiplas previs√µes")
        predictions = [0.65, 0.72, 0.68, 0.75, 0.71]
        interval = calculator.calculate_confidence_interval(predictions)
        
        print(f"Previs√µes: {predictions}")
        print(f"Intervalo de 95%: {interval.lower_bound:.3f} - {interval.upper_bound:.3f}")
        print(f"Formato: {calculator.format_confidence_interval(interval)}")
        
        # Exemplo 3: M√∫ltiplos n√≠veis de confian√ßa
        logger.info("\nüìä Exemplo 3: M√∫ltiplos n√≠veis de confian√ßa")
        confidence_levels = [0.68, 0.80, 0.90, 0.95, 0.99]
        intervals = calculator.calculate_multiple_confidence_levels(predictions, confidence_levels)
        
        print("Intervalos para diferentes n√≠veis de confian√ßa:")
        for level, interval in intervals.items():
            print(f"  {level*100:.0f}%: {interval.lower_bound:.3f} - {interval.upper_bound:.3f}")
        
        # Exemplo 4: An√°lise de incerteza
        logger.info("\nüìä Exemplo 4: An√°lise de incerteza")
        uncertainty = calculator.calculate_prediction_uncertainty(predictions)
        
        print(f"Previs√£o m√©dia: {uncertainty.mean_prediction:.3f}")
        print(f"Score de incerteza: {uncertainty.uncertainty_score:.1f}")
        print(f"Score de confiabilidade: {uncertainty.reliability_score:.1f}")
        print(f"Score de calibra√ß√£o: {uncertainty.calibration_score:.1f}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na demonstra√ß√£o do ConfidenceCalculator: {e}")
        return False

def demo_uncertainty_analyzer():
    """Demonstra o analisador de incerteza"""
    try:
        logger.info("üîç Demonstra√ß√£o do UncertaintyAnalyzer")
        
        # Gerar dados de exemplo
        predictions, actual_values, _ = generate_sample_data(50)
        
        # Criar analisador
        analyzer = UncertaintyAnalyzer()
        
        # Analisar incerteza
        report = analyzer.analyze_prediction_uncertainty(predictions, actual_values)
        
        # Mostrar m√©tricas gerais
        metrics = report.overall_metrics
        print(f"\nüìä M√©tricas Gerais:")
        print(f"  Incerteza m√©dia: {metrics.mean_uncertainty:.1f}")
        print(f"  Score de confiabilidade: {metrics.reliability_score:.1f}")
        print(f"  Score de calibra√ß√£o: {metrics.calibration_score:.1f}")
        print(f"  Taxa de overconfidence: {metrics.overconfidence_rate:.1f}%")
        print(f"  Taxa de underconfidence: {metrics.underconfidence_rate:.1f}%")
        print(f"  Precis√£o das previs√µes: {metrics.prediction_accuracy:.1f}")
        print(f"  Precis√£o da confian√ßa: {metrics.confidence_accuracy:.1f}")
        
        # Mostrar recomenda√ß√µes
        print(f"\nüí° Recomenda√ß√µes:")
        for i, rec in enumerate(report.recommendations, 1):
            print(f"  {i}. {rec}")
        
        # Criar visualiza√ß√µes
        output_dir = "confidence/demo_visualizations"
        analyzer.create_uncertainty_visualizations(output_dir)
        print(f"\nüìä Visualiza√ß√µes criadas em: {output_dir}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na demonstra√ß√£o do UncertaintyAnalyzer: {e}")
        return False

def demo_prediction_intervals():
    """Demonstra o sistema de intervalos de predi√ß√£o"""
    try:
        logger.info("üîç Demonstra√ß√£o do PredictionIntervals")
        
        # Gerar dados de exemplo
        predictions, actual_values, historical_errors = generate_sample_data(30)
        
        # Criar sistema de intervalos
        intervals_system = PredictionIntervals()
        
        # Exemplo 1: Intervalo de predi√ß√£o √∫nico
        logger.info("\nüìä Exemplo 1: Intervalo de predi√ß√£o √∫nico")
        prediction = 0.75
        historical_error = historical_errors[0]
        
        interval = intervals_system.calculate_prediction_interval(
            prediction, historical_error
        )
        
        print(f"Previs√£o: {prediction:.3f}")
        print(f"Intervalo de predi√ß√£o: {interval.lower_bound:.3f} - {interval.upper_bound:.3f}")
        print(f"Largura do intervalo: {interval.interval_width:.3f}")
        print(f"Formato: {intervals_system.format_prediction_interval(interval)}")
        
        # Exemplo 2: M√∫ltiplos intervalos
        logger.info("\nüìä Exemplo 2: M√∫ltiplos intervalos de predi√ß√£o")
        confidence_levels = [0.68, 0.80, 0.90, 0.95, 0.99]
        multiple_intervals = intervals_system.calculate_multiple_prediction_intervals(
            predictions[:5], historical_errors[:5], confidence_levels
        )
        
        print("Intervalos para diferentes n√≠veis de confian√ßa:")
        for level, interval_list in multiple_intervals.items():
            interval = interval_list[0]  # Primeira previs√£o
            print(f"  {level*100:.0f}%: {interval.lower_bound:.3f} - {interval.upper_bound:.3f}")
        
        # Exemplo 3: Avalia√ß√£o de qualidade
        logger.info("\nüìä Exemplo 3: Avalia√ß√£o de qualidade")
        all_intervals = []
        for i, pred in enumerate(predictions[:10]):
            interval = intervals_system.calculate_prediction_interval(
                pred, historical_errors[i]
            )
            all_intervals.append(interval)
        
        metrics = intervals_system.evaluate_prediction_intervals(
            all_intervals, actual_values[:10]
        )
        
        print(f"Taxa de cobertura: {metrics.coverage_rate:.1f}%")
        print(f"Largura m√©dia: {metrics.average_width:.3f}")
        print(f"Score de calibra√ß√£o: {metrics.calibration_score:.1f}")
        print(f"Score de sharpness: {metrics.sharpness_score:.1f}")
        print(f"Score de confiabilidade: {metrics.reliability_score:.1f}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na demonstra√ß√£o do PredictionIntervals: {e}")
        return False

def demo_bootstrap_confidence():
    """Demonstra o sistema de bootstrap"""
    try:
        logger.info("üîç Demonstra√ß√£o do BootstrapConfidence")
        
        # Gerar dados de exemplo
        predictions, actual_values, _ = generate_sample_data(50)
        
        # Criar sistema de bootstrap
        bootstrap_system = BootstrapConfidence(n_bootstrap=500)
        
        # Exemplo 1: Bootstrap b√°sico
        logger.info("\nüìä Exemplo 1: Bootstrap b√°sico")
        data = predictions[:20]
        
        result = bootstrap_system.bootstrap_confidence_interval(
            data, np.mean, "percentile"
        )
        
        print(f"Estat√≠stica original: {result.original_statistic:.3f}")
        print(f"Intervalo de confian√ßa: {result.confidence_interval[0]:.3f} - {result.confidence_interval[1]:.3f}")
        print(f"Vi√©s: {result.bias:.3f}")
        print(f"Erro padr√£o: {result.standard_error:.3f}")
        
        # Exemplo 2: Compara√ß√£o de m√©todos
        logger.info("\nüìä Exemplo 2: Compara√ß√£o de m√©todos")
        methods_comparison = bootstrap_system.compare_bootstrap_methods(
            data, confidence_levels=[0.90, 0.95, 0.99]
        )
        
        print("Compara√ß√£o de m√©todos:")
        for method, levels in methods_comparison.items():
            print(f"  {method}:")
            for level, result in levels.items():
                ci_lower, ci_upper = result.confidence_interval
                print(f"    {level*100:.0f}%: {ci_lower:.3f} - {ci_upper:.3f}")
        
        # Exemplo 3: An√°lise de incerteza
        logger.info("\nüìä Exemplo 3: An√°lise de incerteza")
        uncertainty_analysis = bootstrap_system.bootstrap_uncertainty_analysis(
            predictions, actual_values
        )
        
        quality = uncertainty_analysis['quality_metrics']
        uncertainty = uncertainty_analysis['uncertainty_metrics']
        
        print(f"Vi√©s m√©dio: {quality.mean_bias:.3f}")
        print(f"Taxa de cobertura: {quality.coverage_rate:.1f}%")
        print(f"Efici√™ncia: {quality.efficiency:.1f}")
        print(f"Estabilidade: {quality.stability:.1f}")
        print(f"Incerteza m√©dia: {uncertainty['mean_uncertainty']:.3f}")
        print(f"Precis√£o das previs√µes: {uncertainty['prediction_accuracy']:.1f}")
        
        # Mostrar recomenda√ß√µes
        print(f"\nüí° Recomenda√ß√µes:")
        for i, rec in enumerate(uncertainty_analysis['recommendations'], 1):
            print(f"  {i}. {rec}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na demonstra√ß√£o do BootstrapConfidence: {e}")
        return False

def demo_confidence_visualizer():
    """Demonstra o visualizador de confian√ßa"""
    try:
        logger.info("üîç Demonstra√ß√£o do ConfidenceVisualizer")
        
        # Gerar dados de exemplo
        predictions, actual_values, _ = generate_sample_data(20)
        
        # Criar visualizador
        visualizer = ConfidenceVisualizer()
        
        # Exemplo 1: Intervalos de confian√ßa
        logger.info("\nüìä Exemplo 1: Gr√°fico de intervalos de confian√ßa")
        from confidence.confidence_calculator import ConfidenceCalculator
        calculator = ConfidenceCalculator()
        
        # Calcular intervalos para diferentes n√≠veis
        confidence_levels = [0.68, 0.80, 0.90, 0.95, 0.99]
        intervals = {}
        for level in confidence_levels:
            interval = calculator.calculate_confidence_interval([0.75], confidence_level=level)
            intervals[level] = interval
        
        # Criar gr√°fico
        output_file = "confidence/demo_confidence_intervals.png"
        visualizer.create_confidence_interval_plot(
            intervals, "Intervalos de Confian√ßa - Demonstra√ß√£o", output_file
        )
        print(f"Gr√°fico salvo em: {output_file}")
        
        # Exemplo 2: Fan chart
        logger.info("\nüìä Exemplo 2: Gr√°fico de leque de confian√ßa")
        fan_chart_file = "confidence/demo_fan_chart.png"
        visualizer.create_confidence_fan_chart(
            predictions[:10], confidence_levels, "Fan Chart - Demonstra√ß√£o", fan_chart_file
        )
        print(f"Fan chart salvo em: {fan_chart_file}")
        
        # Exemplo 3: Dashboard de incerteza
        logger.info("\nüìä Exemplo 3: Dashboard de incerteza")
        from confidence.uncertainty_analyzer import UncertaintyAnalyzer
        analyzer = UncertaintyAnalyzer()
        
        # Gerar dados de incerteza
        uncertainty_data = []
        for pred in predictions[:10]:
            uncertainty = calculator.calculate_prediction_uncertainty([pred])
            uncertainty_data.append(uncertainty)
        
        # Criar dashboard
        dashboard_file = "confidence/demo_uncertainty_dashboard.png"
        visualizer.create_uncertainty_dashboard(
            uncertainty_data, "Dashboard de Incerteza - Demonstra√ß√£o", dashboard_file
        )
        print(f"Dashboard salvo em: {dashboard_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erro na demonstra√ß√£o do ConfidenceVisualizer: {e}")
        return False

def create_comprehensive_demo():
    """Cria demonstra√ß√£o abrangente do sistema"""
    try:
        logger.info("üöÄ Iniciando demonstra√ß√£o abrangente do sistema de intervalos de confian√ßa")
        
        # Criar diret√≥rio de sa√≠da
        os.makedirs("confidence/demo_results", exist_ok=True)
        
        # Executar todas as demonstra√ß√µes
        demos = [
            ("ConfidenceCalculator", demo_confidence_calculator),
            ("UncertaintyAnalyzer", demo_uncertainty_analyzer),
            ("PredictionIntervals", demo_prediction_intervals),
            ("BootstrapConfidence", demo_bootstrap_confidence),
            ("ConfidenceVisualizer", demo_confidence_visualizer)
        ]
        
        results = {}
        for name, demo_func in demos:
            logger.info(f"\n{'='*50}")
            logger.info(f"Executando demonstra√ß√£o: {name}")
            logger.info(f"{'='*50}")
            
            try:
                success = demo_func()
                results[name] = success
                if success:
                    logger.info(f"‚úÖ {name} - Demonstra√ß√£o conclu√≠da com sucesso")
                else:
                    logger.error(f"‚ùå {name} - Demonstra√ß√£o falhou")
            except Exception as e:
                logger.error(f"‚ùå {name} - Erro: {e}")
                results[name] = False
        
        # Resumo final
        logger.info(f"\n{'='*50}")
        logger.info("RESUMO DA DEMONSTRA√á√ÉO")
        logger.info(f"{'='*50}")
        
        successful = sum(results.values())
        total = len(results)
        
        for name, success in results.items():
            status = "‚úÖ SUCESSO" if success else "‚ùå FALHOU"
            logger.info(f"{name}: {status}")
        
        logger.info(f"\nTotal: {successful}/{total} demonstra√ß√µes bem-sucedidas")
        
        if successful == total:
            logger.info("üéâ Todas as demonstra√ß√µes foram executadas com sucesso!")
        else:
            logger.warning(f"‚ö†Ô∏è {total - successful} demonstra√ß√µes falharam")
        
        return successful == total
        
    except Exception as e:
        logger.error(f"‚ùå Erro na demonstra√ß√£o abrangente: {e}")
        return False

def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(description="Demonstra√ß√£o de Intervalos de Confian√ßa - MaraBet AI")
    parser.add_argument("--demo", choices=[
        "confidence", "uncertainty", "prediction", "bootstrap", "visualizer", "all"
    ], default="all", help="Tipo de demonstra√ß√£o a executar")
    parser.add_argument("--n-predictions", type=int, default=100, 
                       help="N√∫mero de previs√µes para gerar")
    parser.add_argument("--output-dir", default="confidence/demo_results",
                       help="Diret√≥rio de sa√≠da")
    
    args = parser.parse_args()
    
    # Configurar diret√≥rio de sa√≠da
    os.makedirs(args.output_dir, exist_ok=True)
    
    try:
        if args.demo == "all":
            success = create_comprehensive_demo()
        elif args.demo == "confidence":
            success = demo_confidence_calculator()
        elif args.demo == "uncertainty":
            success = demo_uncertainty_analyzer()
        elif args.demo == "prediction":
            success = demo_prediction_intervals()
        elif args.demo == "bootstrap":
            success = demo_bootstrap_confidence()
        elif args.demo == "visualizer":
            success = demo_confidence_visualizer()
        else:
            logger.error(f"‚ùå Demonstra√ß√£o desconhecida: {args.demo}")
            success = False
        
        if success:
            logger.info("üéâ Demonstra√ß√£o conclu√≠da com sucesso!")
            sys.exit(0)
        else:
            logger.error("‚ùå Demonstra√ß√£o falhou")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è Demonstra√ß√£o cancelada pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Erro inesperado: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
