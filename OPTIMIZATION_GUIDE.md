# üéØ Guia de Otimiza√ß√£o de Hiperpar√¢metros - MaraBet AI

> **Sistema completo de otimiza√ß√£o autom√°tica de hiperpar√¢metros com Optuna e valida√ß√£o cruzada temporal**

## üìã Vis√£o Geral

O MaraBet AI implementa um sistema avan√ßado de otimiza√ß√£o de hiperpar√¢metros que utiliza **Optuna** e **Ray Tune** para encontrar automaticamente as melhores configura√ß√µes para todos os modelos de machine learning. O sistema inclui t√©cnicas avan√ßadas de valida√ß√£o cruzada temporal para s√©ries de dados financeiros.

## üèóÔ∏è Arquitetura do Sistema

### **Componentes Principais**

```
optimization/
‚îú‚îÄ‚îÄ optimizers/                    # Otimizadores de hiperpar√¢metros
‚îÇ   ‚îú‚îÄ‚îÄ hyperparameter_optimizer.py    # Otimizador principal
‚îÇ   ‚îî‚îÄ‚îÄ model_optimizers.py            # Otimizadores espec√≠ficos por modelo
‚îú‚îÄ‚îÄ validation/                    # Valida√ß√£o cruzada temporal
‚îÇ   ‚îî‚îÄ‚îÄ time_series_cv.py              # Implementa√ß√µes de CV temporal
‚îú‚îÄ‚îÄ api/                          # API endpoints
‚îÇ   ‚îî‚îÄ‚îÄ optimization_endpoints.py      # Endpoints FastAPI
‚îú‚îÄ‚îÄ dashboard/                    # Interface web
‚îÇ   ‚îî‚îÄ‚îÄ optimization_dashboard.html    # Dashboard de otimiza√ß√£o
‚îî‚îÄ‚îÄ tests/                        # Testes
    ‚îî‚îÄ‚îÄ test_hyperparameter_optimizer.py
```

### **Tecnologias Utilizadas**

- **Optuna**: Otimiza√ß√£o bayesiana de hiperpar√¢metros
- **Ray Tune**: Otimiza√ß√£o distribu√≠da e paralela
- **Time Series CV**: Valida√ß√£o cruzada temporal avan√ßada
- **Celery**: Execu√ß√£o ass√≠ncrona de otimiza√ß√µes
- **FastAPI**: API REST para controle
- **Bootstrap 5**: Interface web responsiva

## üöÄ Funcionalidades Principais

### **1. Otimiza√ß√£o de Hiperpar√¢metros**

#### **Modelos Suportados**
- **Random Forest**: 10+ par√¢metros otimiz√°veis
- **XGBoost**: 12+ par√¢metros otimiz√°veis
- **LightGBM**: 15+ par√¢metros otimiz√°veis
- **CatBoost**: 10+ par√¢metros otimiz√°veis
- **Regress√£o Log√≠stica**: 6+ par√¢metros otimiz√°veis
- **Rede Neural Bayesiana**: 8+ par√¢metros otimiz√°veis
- **Modelo de Poisson**: 5+ par√¢metros otimiz√°veis

#### **Estrat√©gias de Otimiza√ß√£o**
- **TPE Sampler**: Tree-structured Parzen Estimator
- **Median Pruner**: Poda de tentativas ineficientes
- **Multi-objective**: Otimiza√ß√£o de m√∫ltiplas m√©tricas
- **Pruning**: Interrup√ß√£o precoce de tentativas ruins

### **2. Valida√ß√£o Cruzada Temporal**

#### **Time Series Cross-Validation**
```python
# Janela deslizante
cv = TimeSeriesSplit(
    n_splits=5,
    test_size=20,
    gap=1,  # Evita data leakage
    expanding_window=False
)

# Janela expansiva
cv = TimeSeriesSplit(
    n_splits=5,
    test_size=20,
    expanding_window=True
)
```

#### **Purged Cross-Validation**
```python
# Para dados financeiros
cv = PurgedCrossValidation(
    n_splits=5,
    test_size=20,
    purge_days=1,    # Per√≠odo de purga
    embargo_days=1   # Per√≠odo de embargo
)
```

#### **Walk-Forward Analysis**
```python
# Para estrat√©gias de trading
cv = WalkForwardAnalysis(
    initial_train_size=100,
    step_size=10,
    min_train_size=50
)
```

#### **Monte Carlo Cross-Validation**
```python
# Valida√ß√£o robusta
cv = MonteCarloCrossValidation(
    n_splits=100,
    test_size=0.2,
    random_state=42
)
```

### **3. Execu√ß√£o Ass√≠ncrona**

#### **Tarefas Celery**
- **Otimiza√ß√£o √∫nica**: `optimize_single_model`
- **Otimiza√ß√£o multi-modelo**: `optimize_multiple_models`
- **Otimiza√ß√£o customizada**: `optimize_with_custom_objective`
- **Retomar otimiza√ß√£o**: `resume_optimization`
- **Exportar resultados**: `export_optimization_results`
- **Limpeza**: `cleanup_old_studies`

#### **Filas de Trabalho**
- **ML Queue**: Otimiza√ß√µes de modelos (2 workers)
- **Data Queue**: Processamento de dados (3 workers)
- **Export Queue**: Exporta√ß√£o de resultados (1 worker)

## üõ†Ô∏è Como Usar

### **1. Interface Web**

#### **Acessar Dashboard**
```
http://localhost:8000/optimization
```

#### **Funcionalidades do Dashboard**
- **Iniciar otimiza√ß√µes** (√∫nica ou multi-modelo)
- **Monitorar progresso** em tempo real
- **Visualizar resultados** com gr√°ficos
- **Exportar dados** em m√∫ltiplos formatos
- **Gerenciar estudos** existentes

### **2. API REST**

#### **Iniciar Otimiza√ß√£o √önica**
```bash
curl -X POST "http://localhost:8000/optimization/start-single" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "model_name": "random_forest",
    "study_name": "rf_optimization_1",
    "n_trials": 100,
    "timeout": 3600,
    "cv_strategy": "time_series",
    "scoring": "accuracy"
  }'
```

#### **Iniciar Otimiza√ß√£o Multi-Modelo**
```bash
curl -X POST "http://localhost:8000/optimization/start-multi" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "model_names": ["random_forest", "xgboost", "lightgbm"],
    "study_name": "multi_model_optimization",
    "n_trials": 50,
    "cv_strategy": "purged",
    "scoring": "f1"
  }'
```

#### **Verificar Status**
```bash
curl -X GET "http://localhost:8000/optimization/status/TASK_ID" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

#### **Exportar Resultados**
```bash
curl -X POST "http://localhost:8000/optimization/export" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "study_name": "rf_optimization_1",
    "model_name": "random_forest",
    "export_format": "json"
  }'
```

### **3. Linha de Comando**

#### **Script de Gerenciamento**
```bash
# Listar modelos suportados
python scripts/optimization_manager.py list-models

# Listar estrat√©gias de valida√ß√£o cruzada
python scripts/optimization_manager.py list-cv-strategies

# Listar estudos existentes
python scripts/optimization_manager.py list-studies

# Mostrar detalhes de um estudo
python scripts/optimization_manager.py show-study rf_optimization_1

# Iniciar otimiza√ß√£o √∫nica
python scripts/optimization_manager.py optimize random_forest rf_opt_1 --n-trials 100 --async

# Iniciar otimiza√ß√£o multi-modelo
python scripts/optimization_manager.py optimize-multi random_forest xgboost lightgbm multi_opt_1 --n-trials 50

# Exportar resultados
python scripts/optimization_manager.py export rf_opt_1 random_forest --format json

# Limpar estudos antigos
python scripts/optimization_manager.py cleanup --days 30

# Modo interativo
python scripts/optimization_manager.py interactive
```

### **4. Uso Program√°tico**

#### **Otimiza√ß√£o B√°sica**
```python
from optimization.optimizers.hyperparameter_optimizer import HyperparameterOptimizer
import numpy as np

# Criar dados
X = np.random.randn(1000, 10)
y = np.random.randint(0, 3, 1000)

# Criar otimizador
optimizer = HyperparameterOptimizer(
    study_name="my_optimization",
    n_trials=100,
    cv_strategy="time_series",
    cv_params={"n_splits": 5, "gap": 1},
    scoring="accuracy"
)

# Otimizar Random Forest
study = optimizer.optimize_random_forest(X, y)

# Obter resultados
print(f"Melhor score: {optimizer.get_best_score():.4f}")
print(f"Melhores par√¢metros: {optimizer.get_best_params()}")
```

#### **Otimiza√ß√£o Multi-Modelo**
```python
from optimization.optimizers.hyperparameter_optimizer import MultiModelOptimizer

# Criar otimizador multi-modelo
multi_optimizer = MultiModelOptimizer(
    models=['random_forest', 'xgboost', 'lightgbm'],
    study_name="multi_optimization",
    n_trials=50
)

# Otimizar todos os modelos
results = multi_optimizer.optimize_all(X, y)

# Obter melhor modelo
best_model, best_params, best_score = multi_optimizer.get_best_model()
print(f"Melhor modelo: {best_model} ({best_score:.4f})")
```

#### **Valida√ß√£o Cruzada Customizada**
```python
from optimization.validation.time_series_cv import create_time_series_cv

# Criar valida√ß√£o cruzada personalizada
cv_manager = create_time_series_cv(
    strategy="purged",
    n_splits=5,
    test_size=50,
    purge_days=2,
    embargo_days=1
)

# Usar com otimizador
optimizer = HyperparameterOptimizer(
    study_name="custom_cv_optimization",
    cv_strategy="purged",
    cv_params={"n_splits": 5, "purge_days": 2, "embargo_days": 1}
)
```

## üìä M√©tricas e Monitoramento

### **M√©tricas de Otimiza√ß√£o**

#### **Score de Valida√ß√£o**
- **Accuracy**: Taxa de acerto
- **Precision**: Precis√£o por classe
- **Recall**: Sensibilidade por classe
- **F1-Score**: M√©dia harm√¥nica
- **AUC-ROC**: √Årea sob a curva ROC
- **Log Loss**: Perda logar√≠tmica

#### **M√©tricas Temporais**
- **Time Series Accuracy**: Acur√°cia temporal
- **Walk-Forward Return**: Retorno walk-forward
- **Sharpe Ratio**: Raz√£o de Sharpe
- **Maximum Drawdown**: M√°ximo drawdown

### **Monitoramento em Tempo Real**

#### **Dashboard Web**
- **Progresso**: Barra de progresso em tempo real
- **Gr√°ficos**: Evolu√ß√£o do score ao longo das tentativas
- **Logs**: Log de atividades e erros
- **Status**: Status de cada otimiza√ß√£o

#### **API de Status**
```python
# Verificar status de uma tarefa
response = requests.get(f"/optimization/status/{task_id}")
status = response.json()

print(f"Status: {status['status']}")
print(f"Progresso: {status['info']}")
```

## üîß Configura√ß√£o Avan√ßada

### **Espa√ßos de Hiperpar√¢metros**

#### **Random Forest**
```python
# Par√¢metros otimiz√°veis
{
    'n_estimators': (50, 1000),
    'max_depth': (3, 30),
    'min_samples_split': (2, 20),
    'min_samples_leaf': (1, 10),
    'max_features': ['sqrt', 'log2', None],
    'bootstrap': [True, False],
    'criterion': ['gini', 'entropy']
}
```

#### **XGBoost**
```python
# Par√¢metros otimiz√°veis
{
    'n_estimators': (50, 1000),
    'max_depth': (3, 15),
    'learning_rate': (0.01, 0.3),
    'subsample': (0.6, 1.0),
    'colsample_bytree': (0.6, 1.0),
    'reg_alpha': (0, 10),
    'reg_lambda': (0, 10),
    'gamma': (0, 5)
}
```

#### **LightGBM**
```python
# Par√¢metros otimiz√°veis
{
    'n_estimators': (50, 1000),
    'max_depth': (3, 15),
    'learning_rate': (0.01, 0.3),
    'num_leaves': (10, 300),
    'min_child_samples': (5, 100),
    'subsample': (0.6, 1.0),
    'colsample_bytree': (0.6, 1.0),
    'reg_alpha': (0, 10),
    'reg_lambda': (0, 10)
}
```

### **Configura√ß√£o de Valida√ß√£o Cruzada**

#### **Time Series Split**
```python
# Configura√ß√£o para dados temporais
cv_params = {
    'n_splits': 5,           # N√∫mero de splits
    'test_size': 50,         # Tamanho do teste
    'gap': 1,                # Gap entre treino e teste
    'expanding_window': False, # Janela deslizante
    'min_train_size': 100,   # Tamanho m√≠nimo do treino
    'max_train_size': 500    # Tamanho m√°ximo do treino
}
```

#### **Purged Cross-Validation**
```python
# Configura√ß√£o para dados financeiros
cv_params = {
    'n_splits': 5,           # N√∫mero de splits
    'test_size': 50,         # Tamanho do teste
    'purge_days': 2,         # Dias de purga
    'embargo_days': 1        # Dias de embargo
}
```

### **Configura√ß√£o de Otimiza√ß√£o**

#### **Optuna Sampler**
```python
# TPE Sampler (padr√£o)
sampler = optuna.samplers.TPESampler(
    seed=42,
    n_startup_trials=10,
    n_ei_candidates=24
)

# Grid Sampler
sampler = optuna.samplers.GridSampler(
    search_space={
        'n_estimators': [100, 200, 300],
        'max_depth': [5, 10, 15]
    }
)
```

#### **Pruning**
```python
# Median Pruner (padr√£o)
pruner = optuna.pruners.MedianPruner(
    n_startup_trials=5,
    n_warmup_steps=10,
    interval_steps=1
)

# Successive Halving Pruner
pruner = optuna.pruners.SuccessiveHalvingPruner(
    min_resource=1,
    reduction_factor=4,
    min_early_stopping_rate=0
)
```

## üìà Exemplos Pr√°ticos

### **1. Otimiza√ß√£o para Dados Temporais**

```python
# Configura√ß√£o para s√©ries temporais
optimizer = HyperparameterOptimizer(
    study_name="temporal_optimization",
    n_trials=200,
    cv_strategy="time_series",
    cv_params={
        "n_splits": 5,
        "test_size": 100,
        "gap": 2,
        "expanding_window": False
    },
    scoring="accuracy"
)

# Otimizar XGBoost
study = optimizer.optimize_xgboost(X, y)
```

### **2. Otimiza√ß√£o para Dados Financeiros**

```python
# Configura√ß√£o para dados financeiros
optimizer = HyperparameterOptimizer(
    study_name="financial_optimization",
    n_trials=300,
    cv_strategy="purged",
    cv_params={
        "n_splits": 5,
        "test_size": 50,
        "purge_days": 3,
        "embargo_days": 2
    },
    scoring="f1"
)

# Otimizar LightGBM
study = optimizer.optimize_lightgbm(X, y)
```

### **3. Otimiza√ß√£o Multi-Objetivo**

```python
# Configura√ß√£o multi-objetivo
def multi_objective(trial):
    # Definir hiperpar√¢metros
    params = ModelOptimizerFactory.suggest_hyperparameters(
        'random_forest', trial
    )
    
    # Criar modelo
    model = RandomForestClassifier(**params)
    
    # Valida√ß√£o cruzada
    cv_results = cv_manager.cross_validate(model, X, y)
    
    # Retornar m√∫ltiplas m√©tricas
    return cv_results['test_score'].mean(), -cv_results['test_score'].std()

# Criar estudo multi-objetivo
study = optuna.create_study(
    directions=['maximize', 'maximize'],
    sampler=optuna.samplers.TPESampler()
)

study.optimize(multi_objective, n_trials=100)
```

### **4. Otimiza√ß√£o com Callbacks**

```python
# Callback para monitoramento
def callback(study, trial):
    if trial.number % 10 == 0:
        print(f"Trial {trial.number}: {trial.value:.4f}")
    
    # Salvar checkpoint
    if trial.number % 50 == 0:
        optimizer.save_study(f"checkpoint_{trial.number}.pkl")

# Otimizar com callback
study = optimizer.optimize_random_forest(X, y, callback=callback)
```

## üß™ Testes e Valida√ß√£o

### **Executar Testes**

```bash
# Testes unit√°rios
pytest optimization/tests/test_hyperparameter_optimizer.py -v

# Testes com cobertura
pytest optimization/tests/ --cov=optimization --cov-report=html

# Testes espec√≠ficos
pytest optimization/tests/ -m optimization -v
```

### **Testes de Integra√ß√£o**

```python
# Teste de otimiza√ß√£o completa
def test_end_to_end_optimization():
    X, y = create_test_data()
    
    optimizer = HyperparameterOptimizer(
        study_name="integration_test",
        n_trials=10
    )
    
    study = optimizer.optimize_random_forest(X, y)
    
    assert study is not None
    assert len(study.trials) == 10
    assert optimizer.get_best_score() > 0
```

## üöÄ Deploy e Produ√ß√£o

### **Configura√ß√£o de Produ√ß√£o**

#### **Docker Compose**
```yaml
# Adicionar ao docker-compose.yml
services:
  optimization-worker:
    build: .
    command: celery -A tasks.celery_app worker -l info -Q optimization
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
    volumes:
      - ./optimization:/app/optimization
```

#### **Vari√°veis de Ambiente**
```bash
# Configura√ß√£o de otimiza√ß√£o
OPTIMIZATION_STORAGE_URL=postgresql://user:pass@localhost/optimization
OPTIMIZATION_N_TRIALS=100
OPTIMIZATION_TIMEOUT=3600
OPTIMIZATION_CV_STRATEGY=time_series
```

### **Monitoramento de Produ√ß√£o**

#### **M√©tricas Importantes**
- **Taxa de conclus√£o**: % de otimiza√ß√µes conclu√≠das
- **Tempo m√©dio**: Tempo m√©dio por otimiza√ß√£o
- **Melhor score**: Melhor score encontrado
- **Uso de recursos**: CPU, mem√≥ria, disco

#### **Alertas**
- **Falhas de otimiza√ß√£o**: > 10% de falhas
- **Tempo excessivo**: > 2 horas por otimiza√ß√£o
- **Uso de disco**: > 80% de uso
- **Erros de valida√ß√£o**: > 5% de erros

## üìö Refer√™ncias e Recursos

### **Documenta√ß√£o Oficial**
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Ray Tune Documentation](https://docs.ray.io/en/latest/tune/)
- [Scikit-learn Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)

### **Artigos Cient√≠ficos**
- "Optuna: A Next-generation Hyperparameter Optimization Framework" (2019)
- "Time Series Cross-Validation for Machine Learning" (2020)
- "Purged Cross-Validation for Financial Data" (2018)

### **Tutoriais**
- [Hyperparameter Optimization with Optuna](https://optuna.readthedocs.io/en/stable/tutorial/)
- [Time Series Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html#time-series-split)

---

## üéâ **SISTEMA DE OTIMIZA√á√ÉO COMPLETO!**

**Status**: ‚úÖ **PRONTO PARA PRODU√á√ÉO**

O MaraBet AI agora possui um sistema completo de otimiza√ß√£o de hiperpar√¢metros que:

- **Automatiza** a busca pelos melhores par√¢metros
- **Utiliza** t√©cnicas avan√ßadas de valida√ß√£o cruzada temporal
- **Suporta** todos os modelos de ML do sistema
- **Executa** otimiza√ß√µes de forma ass√≠ncrona
- **Monitora** progresso em tempo real
- **Exporta** resultados em m√∫ltiplos formatos

**üéØ Desenvolvido com ‚ù§Ô∏è para m√°xima performance e precis√£o**
