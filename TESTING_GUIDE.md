# ğŸ§ª Guia de Testes - MaraBet AI

> **Sistema completo de testes unitÃ¡rios e de integraÃ§Ã£o para o MaraBet AI**

## ğŸ“‹ VisÃ£o Geral

O MaraBet AI implementa uma suÃ­te abrangente de testes que garante a qualidade, confiabilidade e robustez do sistema. Os testes cobrem desde funÃ§Ãµes individuais atÃ© fluxos completos de integraÃ§Ã£o.

## ğŸ—ï¸ Estrutura de Testes

### **OrganizaÃ§Ã£o dos Testes**

```
tests/
â”œâ”€â”€ conftest.py                 # ConfiguraÃ§Ã£o global e fixtures
â”œâ”€â”€ test_units/                 # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_ml_models.py      # Testes de modelos ML
â”‚   â””â”€â”€ test_utilities.py      # Testes de funÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ test_integration/           # Testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ test_pipeline.py       # Pipeline completo
â”‚   â””â”€â”€ test_auth_integration.py # AutenticaÃ§Ã£o
â””â”€â”€ utils/                      # UtilitÃ¡rios de teste
    â””â”€â”€ test_helpers.py         # Helpers e fixtures
```

### **Tipos de Testes**

1. **Testes UnitÃ¡rios** (`test_units/`)
   - LÃ³gica de ML e algoritmos
   - FunÃ§Ãµes de utilidade
   - ValidaÃ§Ãµes e cÃ¡lculos
   - Modelos de dados

2. **Testes de IntegraÃ§Ã£o** (`test_integration/`)
   - Pipeline completo de coleta-processamento-prediÃ§Ã£o
   - IntegraÃ§Ã£o com APIs externas
   - Fluxos de autenticaÃ§Ã£o
   - IntegraÃ§Ã£o com banco de dados

3. **Testes de API** (`test_integration/`)
   - Endpoints REST
   - ValidaÃ§Ã£o de dados
   - Controle de acesso
   - Tratamento de erros

## ğŸš€ Como Executar Testes

### **1. ExecuÃ§Ã£o BÃ¡sica**

```bash
# Executar todos os testes
pytest

# Executar com cobertura
pytest --cov=. --cov-report=html

# Executar testes especÃ­ficos
pytest tests/test_units/test_ml_models.py

# Executar com marcadores
pytest -m unit
pytest -m integration
pytest -m ml
pytest -m auth
```

### **2. Scripts de ExecuÃ§Ã£o**

```bash
# Usar script personalizado
python scripts/run_tests.py all --parallel --coverage

# Executar tipos especÃ­ficos
python scripts/run_tests.py unit
python scripts/run_tests.py integration
python scripts/run_tests.py ml
python scripts/run_tests.py auth

# Executar no CI
python scripts/ci_tests.py
```

### **3. ExecuÃ§Ã£o Paralela**

```bash
# Executar em paralelo (automÃ¡tico)
pytest -n auto

# Executar com nÃºmero especÃ­fico de workers
pytest -n 4

# Executar sequencialmente
pytest -n 0
```

## ğŸ“Š Cobertura de Testes

### **Threshold de Cobertura**

- **MÃ­nimo**: 80%
- **Meta**: 90%
- **Ideal**: 95%

### **RelatÃ³rios de Cobertura**

```bash
# Gerar relatÃ³rio HTML
pytest --cov=. --cov-report=html:htmlcov

# Gerar relatÃ³rio XML (para CI)
pytest --cov=. --cov-report=xml:coverage.xml

# Gerar relatÃ³rio terminal
pytest --cov=. --cov-report=term-missing
```

### **Verificar Cobertura**

```bash
# Verificar se atende ao threshold
coverage report --fail-under=80

# Gerar relatÃ³rio final
coverage html -d htmlcov/final
```

## ğŸ§ª Testes UnitÃ¡rios

### **Testes de ML**

```python
# Exemplo: Teste de modelo Random Forest
def test_random_forest_training(sample_ml_data):
    model = RandomForestModel()
    model.fit(sample_ml_data['X_train'], sample_ml_data['y_train'])
    
    assert model.is_trained == True
    assert hasattr(model, 'model')

def test_random_forest_prediction(sample_ml_data):
    model = RandomForestModel()
    model.fit(sample_ml_data['X_train'], sample_ml_data['y_train'])
    
    predictions = model.predict(sample_ml_data['X_test'])
    
    assert len(predictions) == len(sample_ml_data['X_test'])
    assert all(pred in [0, 1, 2] for pred in predictions)
```

### **Testes de Utilidades**

```python
# Exemplo: Teste de cÃ¡lculo de probabilidade
def test_calculate_implied_probability():
    calculator = ProbabilityCalculator()
    
    prob = calculator.calculate_implied_probability(2.0)
    assert abs(prob - 0.5) < 1e-10

def test_calculate_expected_value():
    calculator = ProbabilityCalculator()
    
    ev = calculator.calculate_expected_value(0.6, 2.0)
    expected = 0.6 * 2.0 - 1  # 0.2
    assert abs(ev - expected) < 1e-10
```

## ğŸ”— Testes de IntegraÃ§Ã£o

### **Pipeline Completo**

```python
# Exemplo: Teste de pipeline completo
def test_complete_value_bet_pipeline(test_db, mock_api_football, mock_odds_api):
    # 1. Coletar dados de partidas
    api_collector = APIFootballCollector()
    fixtures_result = api_collector.collect_fixtures(league_id=39, season=2024)
    assert fixtures_result['success'] == True
    
    # 2. Coletar odds
    odds_collector = OddsCollector()
    odds_result = odds_collector.collect_odds(sport="soccer_epl", regions=["uk"])
    assert odds_result['success'] == True
    
    # 3. Processar dados
    processor = DataProcessor()
    processing_result = processor.process_matches()
    assert processing_result['success'] == True
    
    # 4. Treinar modelo ML
    manager = MLModelManager()
    model = manager.create_model('random_forest')
    training_result = manager.train_model(model, X_train, y_train)
    assert training_result is not None
    
    # 5. Fazer prediÃ§Ã£o
    calculator = ProbabilityCalculator()
    probability = calculator.calculate_probability(model, X_test)
    assert 0 <= probability <= 1
    
    # 6. Identificar value bet
    identifier = ValueIdentifier()
    prediction_data = {
        'predicted_probability': probability,
        'current_odd': 2.10,
        'confidence': 0.8,
        'min_ev_threshold': 0.1,
        'min_confidence_threshold': 0.7
    }
    
    is_value_bet = identifier.identify_value_bet(prediction_data)
    assert isinstance(is_value_bet, bool)
```

### **Testes de AutenticaÃ§Ã£o**

```python
# Exemplo: Teste de fluxo de login
def test_user_login_flow(test_client, test_user):
    login_data = {
        "username": test_user.username,
        "password": "testpass123",
        "remember_me": False
    }
    
    response = test_client.post("/auth/login", json=login_data)
    
    assert response.status_code == 200
    data = response.json()
    assert "access_token" in data
    assert "refresh_token" in data
    assert data["token_type"] == "bearer"
```

## ğŸ› ï¸ Fixtures e Helpers

### **Fixtures Principais**

```python
# Banco de dados de teste
@pytest.fixture(scope="function")
def test_db(test_db_engine):
    session = TestingSessionLocal()
    yield session
    session.close()

# Cliente FastAPI
@pytest.fixture(scope="function")
def test_client(test_db):
    def override_get_db():
        yield test_db
    
    app.dependency_overrides[get_db] = override_get_db
    with TestClient(app) as client:
        yield client
    app.dependency_overrides.clear()

# Redis de teste
@pytest.fixture(scope="function")
def test_redis():
    cache = RedisCache(host="localhost", port=6379, db=1)
    cache.clear_all()
    yield cache
    cache.clear_all()
```

### **Helpers de Dados**

```python
# Criar dados de teste
def create_test_match_data(fixture_id=12345, **kwargs):
    default_data = {
        "fixture_id": fixture_id,
        "league_name": "Premier League",
        "home_team_name": "Manchester United",
        "away_team_name": "Liverpool",
        "date": datetime.now() + timedelta(hours=2),
        "status": "NS"
    }
    default_data.update(kwargs)
    return default_data

# Criar dataset de ML
def create_test_ml_dataset(n_samples=100, n_features=10, n_classes=3):
    X = np.random.rand(n_samples, n_features)
    y = np.random.randint(0, n_classes, n_samples)
    
    split_idx = int(n_samples * 0.8)
    return {
        "X_train": X[:split_idx],
        "y_train": y[:split_idx],
        "X_test": X[split_idx:],
        "y_test": y[split_idx:]
    }
```

## ğŸ·ï¸ Marcadores de Teste

### **Marcadores DisponÃ­veis**

```python
# Marcadores por tipo
@pytest.mark.unit
def test_unit_function():
    pass

@pytest.mark.integration
def test_integration_flow():
    pass

@pytest.mark.ml
def test_ml_model():
    pass

@pytest.mark.auth
def test_authentication():
    pass

@pytest.mark.api
def test_api_endpoint():
    pass

# Marcadores por caracterÃ­stica
@pytest.mark.slow
def test_slow_operation():
    pass

@pytest.mark.external
def test_external_api():
    pass

@pytest.mark.database
def test_database_operation():
    pass

@pytest.mark.redis
def test_redis_operation():
    pass

@pytest.mark.celery
def test_celery_task():
    pass
```

### **Executar por Marcadores**

```bash
# Executar apenas testes unitÃ¡rios
pytest -m unit

# Executar apenas testes de integraÃ§Ã£o
pytest -m integration

# Executar apenas testes de ML
pytest -m ml

# Executar apenas testes de autenticaÃ§Ã£o
pytest -m auth

# Executar apenas testes de API
pytest -m api

# Executar apenas testes lentos
pytest -m slow

# Executar apenas testes externos
pytest -m external

# Excluir testes lentos
pytest -m "not slow"

# Excluir testes externos
pytest -m "not external"
```

## ğŸ”§ ConfiguraÃ§Ã£o de Testes

### **Arquivo pytest.ini**

```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

markers =
    unit: marca testes unitÃ¡rios
    integration: marca testes de integraÃ§Ã£o
    slow: marca testes lentos
    ml: marca testes de machine learning
    auth: marca testes de autenticaÃ§Ã£o
    api: marca testes de API

addopts = 
    --cov=.
    --cov-report=html:htmlcov
    --cov-report=term-missing
    --cov-report=xml:coverage.xml
    --cov-fail-under=80
    --strict-markers
    --disable-warnings
    --tb=short
    -v

cov-branch = true
cov-source = .

cov-omit = 
    tests/*
    */migrations/*
    */venv/*
    */env/*
    */__pycache__/*
    */site-packages/*
    setup.py
    conftest.py
```

### **VariÃ¡veis de Ambiente**

```bash
# ConfiguraÃ§Ãµes de teste
export TEST_DATABASE_URL="sqlite:///./test_sports_data.db"
export TEST_REDIS_URL="redis://localhost:6379/1"
export API_FOOTBALL_KEY="test_key"
export THE_ODDS_API_KEY="test_key"
export TELEGRAM_BOT_TOKEN="test_token"
export TELEGRAM_CHAT_ID="test_chat"
```

## ğŸ“ˆ MÃ©tricas e RelatÃ³rios

### **RelatÃ³rios Gerados**

1. **HTML Coverage Report** (`htmlcov/index.html`)
   - Cobertura visual por arquivo
   - Linhas cobertas/nÃ£o cobertas
   - MÃ©tricas detalhadas

2. **XML Coverage Report** (`coverage.xml`)
   - Para integraÃ§Ã£o com CI/CD
   - CompatÃ­vel com Codecov

3. **JUnit XML** (`test-results.xml`)
   - Resultados de testes
   - Para integraÃ§Ã£o com CI/CD

4. **JSON Report** (`test-report.json`)
   - Dados estruturados
   - Para anÃ¡lise programÃ¡tica

### **MÃ©tricas Importantes**

- **Cobertura de CÃ³digo**: % de linhas executadas
- **Cobertura de Branches**: % de branches testados
- **Tempo de ExecuÃ§Ã£o**: DuraÃ§Ã£o dos testes
- **Taxa de Sucesso**: % de testes que passaram
- **Testes por Segundo**: Velocidade de execuÃ§Ã£o

## ğŸš¨ Tratamento de Erros

### **Testes que Falham**

```python
# Verificar exceÃ§Ãµes especÃ­ficas
def test_invalid_input():
    with pytest.raises(ValueError, match="Invalid input"):
        process_invalid_data("invalid")

# Verificar mÃºltiplas exceÃ§Ãµes
def test_multiple_exceptions():
    with pytest.raises((ValueError, TypeError)):
        process_data(None)
```

### **Testes de Timeout**

```python
# Teste com timeout
@pytest.mark.timeout(30)
def test_slow_operation():
    result = slow_operation()
    assert result is not None
```

### **Testes Condicionais**

```python
# Teste condicional
@pytest.mark.skipif(not redis_available(), reason="Redis not available")
def test_redis_operation():
    cache = RedisCache()
    assert cache.ping() == True
```

## ğŸ”„ IntegraÃ§Ã£o com CI/CD

### **GitHub Actions**

```yaml
# Exemplo de workflow
- name: Run Tests
  run: |
    pytest tests/ \
      --cov=. \
      --cov-report=xml:coverage.xml \
      --cov-report=html:htmlcov \
      --junitxml=test-results.xml \
      --html=test-report.html \
      --self-contained-html \
      -v
```

### **ExecuÃ§Ã£o Paralela no CI**

```yaml
# Executar testes em paralelo
- name: Run Parallel Tests
  run: |
    pytest tests/ -n auto \
      --cov=. \
      --cov-report=xml:coverage.xml \
      --junitxml=test-results.xml \
      -v
```

## ğŸ“š Boas PrÃ¡ticas

### **1. Nomenclatura**

```python
# Nomes descritivos
def test_calculate_expected_value_with_positive_ev():
    pass

def test_user_login_with_valid_credentials():
    pass

def test_api_returns_404_for_invalid_endpoint():
    pass
```

### **2. OrganizaÃ§Ã£o**

```python
# Agrupar testes relacionados
class TestMLModelManager:
    def test_create_model(self):
        pass
    
    def test_train_model(self):
        pass
    
    def test_predict(self):
        pass
```

### **3. Fixtures**

```python
# Usar fixtures para setup/teardown
@pytest.fixture
def sample_data():
    # Setup
    data = create_test_data()
    yield data
    # Teardown
    cleanup_test_data(data)
```

### **4. Assertions**

```python
# Assertions especÃ­ficas
def test_calculation():
    result = calculate_value(10, 20)
    assert result == 30
    assert isinstance(result, int)
    assert result > 0
```

### **5. Mocks**

```python
# Usar mocks para dependÃªncias externas
@patch('requests.get')
def test_api_call(mock_get):
    mock_get.return_value.json.return_value = {"data": "test"}
    
    result = call_external_api()
    
    assert result == {"data": "test"}
    mock_get.assert_called_once()
```

## ğŸ¯ Objetivos de Qualidade

### **MÃ©tricas de Qualidade**

- **Cobertura de CÃ³digo**: â‰¥ 80%
- **Cobertura de Branches**: â‰¥ 70%
- **Tempo de ExecuÃ§Ã£o**: < 5 minutos
- **Taxa de Sucesso**: â‰¥ 95%
- **Testes por Arquivo**: â‰¥ 5

### **Tipos de Testes por Categoria**

- **ML Models**: 20+ testes
- **Utilities**: 30+ testes
- **API Endpoints**: 50+ testes
- **Authentication**: 25+ testes
- **Integration**: 15+ testes

## ğŸš€ PrÃ³ximos Passos

### **Melhorias Planejadas**

1. **Testes de Performance**
   - Benchmarks de ML
   - Testes de carga
   - Testes de memÃ³ria

2. **Testes de SeguranÃ§a**
   - Testes de vulnerabilidades
   - Testes de autenticaÃ§Ã£o
   - Testes de autorizaÃ§Ã£o

3. **Testes de Usabilidade**
   - Testes de interface
   - Testes de experiÃªncia do usuÃ¡rio
   - Testes de acessibilidade

4. **Testes de Compatibilidade**
   - Testes de versÃµes Python
   - Testes de sistemas operacionais
   - Testes de navegadores

---

## ğŸ‰ **SISTEMA DE TESTES COMPLETO!**

**Status**: âœ… **PRONTO PARA PRODUÃ‡ÃƒO**

O MaraBet AI agora possui uma suÃ­te completa de testes unitÃ¡rios e de integraÃ§Ã£o, garantindo qualidade, confiabilidade e robustez do sistema!

**ğŸ§ª Desenvolvido com â¤ï¸ para qualidade e confiabilidade**
